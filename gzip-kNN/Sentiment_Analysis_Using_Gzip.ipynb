{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is a surprisingly effective algorithm for sentiment analysis. It is surprising not because it works particularly well, but because it works at all.\n",
        "\n",
        "I originally saw this video by Sentdex (https://www.youtube.com/watch?v=jkdWzvMOPuo) and wanted to try it on some different data sets and give it a go for myself.\n",
        "\n",
        "The basic idea is that you can do rudimentary sentiment analysis by using k-nearest-neighbours on the length of the input after being compressed. I do not intend to question why this works, I was just interested in seeing that it worked on a variety of different data sets.\n",
        "\n",
        "With this in mind, I googled 'datasets for sentiment analysis' and found these data sets: https://www.kaggle.com/datasets/marklvl/sentiment-labelled-sentences-data-set?resource=download https://www.kaggle.com/datasets/cosmos98/twitter-and-reddit-sentimental-analysis-dataset"
      ],
      "metadata": {
        "id": "SVQKobO07S9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"sentiment analysis.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"sentiment analysis\")"
      ],
      "metadata": {
        "id": "1H87c5Kkx9K8"
      },
      "execution_count": 422,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To start, I load the data into a dataframe (the csv versions of the files are a little weird so I did it with the text versions of the files). I then shuffle the data about with df.sample(frac = 1) which shuffles the data and returns the whole data frame.\n",
        "\n",
        "I reset the index, then split the dataframe into training and test sets. I have found that somewhere between 60 and 80 percent of the data tends to give good results."
      ],
      "metadata": {
        "id": "myPB6vu58tmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "file_path = \"sentiment analysis/sentiment labelled sentences/amazon_cells_labelled.txt\"\n",
        "df = pd.read_csv(file_path, sep=\"\\t\", lineterminator=\"\\n\", header=None, names=[\"Sentence\", \"Sentiment\"])\n",
        "\n",
        "df = df.sample(frac = 1).reset_index()\n",
        "train_split = 0.75\n",
        "\n",
        "train = df.loc[0:math.floor((len(df)*train_split))-1]\n",
        "test = df.loc[math.ceil(len(df)*train_split):len(df)]"
      ],
      "metadata": {
        "id": "NoVITMkQyWrg"
      },
      "execution_count": 423,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function allows us to compare the lengths of two compressed strings. We have to normalise the lengths to get the 'distance' between the two strings.\n",
        "\n",
        "NCD means normalised compression differences, Sentdex covers this in more detail."
      ],
      "metadata": {
        "id": "uwgn37l69U6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "\n",
        "def ncd(str1: str, str2: str) -> float:\n",
        "\n",
        "  str1_compressed = len(gzip.compress(bytes(str1, 'utf-8')))\n",
        "  str2_compressed = len(gzip.compress(bytes(str2, 'utf-8')))\n",
        "\n",
        "  str1str2 = len(gzip.compress(bytes(\" \".join([str1,str2]), 'utf-8')))\n",
        "\n",
        "  return (str1str2 - min(str1_compressed, str2_compressed)) / max(str1_compressed, str2_compressed)"
      ],
      "metadata": {
        "id": "D8H7dT4UOfDY"
      },
      "execution_count": 424,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line of code calculates the NCD to every point in the training data set, for every point in the test data set. This line is the slowest part of the code, as it does all the heavy lifting.\n",
        "\n",
        "There is probably a good optimisation for this, as at the moment I think it is O(N*M) where N is the number of samples in the test data set and M is the number of samples in the training data set.\n",
        "\n",
        "Seeing as we are only interested in the k closest points, you could probably do a tree map optimisation and that would definitely speed it up a lot for larger data sets."
      ],
      "metadata": {
        "id": "6foumry89swA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ncds = [[ncd(j, i) for j in train['Sentence']] for i in test['Sentence']]"
      ],
      "metadata": {
        "id": "QIDHxkEBxmyO"
      },
      "execution_count": 425,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is my (very) rudimentary implementation of k nearest neighbouts. You can pass in the pre-calculated ncds, or they can be recalculated with every use of the function.\n",
        "\n",
        "We loop through every test point in ncds, collecting the sentiment value for its k nearest neighbours, before taking the average of all the sentiment values for that test point and then rounding to the nearest whole number. This represents the prediction of the algorithm. This is appended to a predictions array, which is ultimately returned after predicting for all the test points."
      ],
      "metadata": {
        "id": "WWuKF6tA-jwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import average\n",
        "import copy\n",
        "\n",
        "def kNN(k: int, train: pd.DataFrame, test: pd.DataFrame, ncds: list() = None) -> list():\n",
        "\n",
        "  predictions = []\n",
        "  temp_ncds = copy.deepcopy(ncds)\n",
        "  if(temp_ncds == None):\n",
        "    temp_ncds = [[ncd(j, i) for j in train['Sentence']] for i in test['Sentence']]\n",
        "\n",
        "  for testSample in temp_ncds:\n",
        "\n",
        "    sentiments = []\n",
        "    for _ in range(k):\n",
        "\n",
        "      nearestNeighbourIndex = testSample.index(min(testSample))\n",
        "      sentiments.append(train['Sentiment'][nearestNeighbourIndex])\n",
        "      testSample[nearestNeighbourIndex] = float(\"inf\")\n",
        "\n",
        "    predictions.append(round(average(sentiments)))\n",
        "\n",
        "  return predictions"
      ],
      "metadata": {
        "id": "9F_jlzjR890L"
      },
      "execution_count": 426,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block tests the algorithm for different values of k from 1 to 15, printing out the accuracy of the algorithm at the end. Randomly assigning sentiment would result in a score of around 50% for this dataset. In my tests, this algorithm consistently score above 60%, with k=3 and k=5 frequently nearing 70%."
      ],
      "metadata": {
        "id": "Y9iNckyS_dob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(1, 16, 2):\n",
        "  preds = kNN(k, train, test, ncds)\n",
        "  score = sum([1 for i in range(len(preds)) if preds[i] == test['Sentiment'][i+math.ceil(len(df)*train_split)]])\n",
        "  accuracy = score / len(test)\n",
        "  print(\"Accuracy at k =\", k, \":\", round(accuracy*100, 2), \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ets3hE8EMsGO",
        "outputId": "aa156d9e-7d0b-4d14-9e0f-03c14b9c83bb"
      },
      "execution_count": 427,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy at k = 1 : 65.2 %\n",
            "Accuracy at k = 3 : 68.4 %\n",
            "Accuracy at k = 5 : 66.8 %\n",
            "Accuracy at k = 7 : 66.8 %\n",
            "Accuracy at k = 9 : 64.0 %\n",
            "Accuracy at k = 11 : 64.0 %\n",
            "Accuracy at k = 13 : 64.4 %\n",
            "Accuracy at k = 15 : 62.4 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The rest of this notebook just applies the technique to different data sets. This dataset comes from imdb."
      ],
      "metadata": {
        "id": "_QrIWNEzAA5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"sentiment analysis/sentiment labelled sentences/imdb_labelled.txt\"\n",
        "df = pd.read_csv(file_path, sep=\"\\t\", lineterminator=\"\\n\", header=None, names=[\"Sentence\", \"Sentiment\"])\n",
        "\n",
        "df = df.sample(frac = 1).reset_index()\n",
        "\n",
        "train = df.loc[0:math.floor((len(df)*train_split))-1]\n",
        "test = df.loc[math.ceil(len(df)*train_split):len(df)]"
      ],
      "metadata": {
        "id": "1-iguQVEr6hy"
      },
      "execution_count": 428,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ncds = [[ncd(j, i) for j in train['Sentence']] for i in test['Sentence']]"
      ],
      "metadata": {
        "id": "aKY6HA5Dsg_2"
      },
      "execution_count": 429,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Randomly assigning sentiment would result in a score of around 50% for this dataset. In my tests, this algorithm consistently score above 60%, with k=3 and k=5 frequently getting to 66%-67%."
      ],
      "metadata": {
        "id": "9LDM6vwNBBuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(1, 16, 2):\n",
        "  preds = kNN(k, train, test, ncds)\n",
        "  score = sum([1 for i in range(len(preds)) if preds[i] == test['Sentiment'][i+math.ceil(len(df)*train_split)]])\n",
        "  accuracy = score / len(test)\n",
        "  print(\"Accuracy at k =\", k, \":\", round(accuracy*100, 2), \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-RJ2YgZsjxj",
        "outputId": "d16ecb47-d83f-42d2-e3e0-8e833aa045d8"
      },
      "execution_count": 430,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy at k = 1 : 60.96 %\n",
            "Accuracy at k = 3 : 67.38 %\n",
            "Accuracy at k = 5 : 63.64 %\n",
            "Accuracy at k = 7 : 66.31 %\n",
            "Accuracy at k = 9 : 64.17 %\n",
            "Accuracy at k = 11 : 66.31 %\n",
            "Accuracy at k = 13 : 68.98 %\n",
            "Accuracy at k = 15 : 63.64 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"sentiment analysis/sentiment labelled sentences/yelp_labelled.txt\"\n",
        "df = pd.read_csv(file_path, sep=\"\\t\", lineterminator=\"\\n\", header=None, names=[\"Sentence\", \"Sentiment\"])\n",
        "\n",
        "df = df.sample(frac = 1).reset_index()\n",
        "\n",
        "train = df.loc[0:math.floor((len(df)*train_split))-1]\n",
        "test = df.loc[math.ceil(len(df)*train_split):len(df)]"
      ],
      "metadata": {
        "id": "SoWIqV7jsp_9"
      },
      "execution_count": 431,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ncds = [[ncd(j, i) for j in train['Sentence']] for i in test['Sentence']]"
      ],
      "metadata": {
        "id": "qIcwmQXOsuPH"
      },
      "execution_count": 432,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Randomly assigning sentiment would result in a score of around 50% for this dataset. In my tests, this algorithm consistently score above 60%, with k=3 and k=5 frequently getting to 62%-63%.\n",
        "\n",
        "Interesting to note that the algorithm is less effective for this dataset from yelp, than it was for either amazon reviews or imdb."
      ],
      "metadata": {
        "id": "qkROPNUiBPg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(1, 16, 2):\n",
        "  preds = kNN(k, train, test, ncds)\n",
        "  score = sum([1 for i in range(len(preds)) if preds[i] == test['Sentiment'][i+math.ceil(len(df)*train_split)]])\n",
        "  accuracy = score / len(test)\n",
        "  print(\"Accuracy at k =\", k, \":\", round(accuracy*100, 2), \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjHQ6m-bsv3Z",
        "outputId": "22d83343-b56d-4ba5-b1ca-7f36dc8691ca"
      },
      "execution_count": 433,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy at k = 1 : 66.0 %\n",
            "Accuracy at k = 3 : 62.0 %\n",
            "Accuracy at k = 5 : 63.2 %\n",
            "Accuracy at k = 7 : 60.8 %\n",
            "Accuracy at k = 9 : 61.6 %\n",
            "Accuracy at k = 11 : 62.8 %\n",
            "Accuracy at k = 13 : 63.6 %\n",
            "Accuracy at k = 15 : 63.2 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile(\"twitter+reddit.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"twitter+reddit\")"
      ],
      "metadata": {
        "id": "lTgOakzdvm3p"
      },
      "execution_count": 434,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These next two datasets are slightly different than the first three, they have positive, negative and neutral sentiment labels attached. They are also several orders of magnitude larger. This means when I shuffle the data, I'm actually only using frac = 0.05 so I get a random 5% of the data to work with. This leads to more variability."
      ],
      "metadata": {
        "id": "A19xOm6fBf6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"twitter+reddit/Reddit_Data.csv\"\n",
        "df = pd.read_csv(file_path, sep=\",\", lineterminator=\"\\n\", names=[\"Sentence\", \"Sentiment\"])\n",
        "\n",
        "df = df.sample(frac = 0.05).reset_index()\n",
        "train_split = 0.75\n",
        "\n",
        "df['Sentence'] = df['Sentence'].astype('string')\n",
        "df['Sentiment'] = df['Sentiment'].astype('int')\n",
        "\n",
        "train = df.loc[0:math.floor((len(df)*train_split))-1]\n",
        "test = df.loc[math.ceil(len(df)*train_split):len(df)]"
      ],
      "metadata": {
        "id": "AeguTw5mvmu-"
      },
      "execution_count": 483,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ncds = [[ncd(str(j), str(i)) for j in train['Sentence']] for i in test['Sentence']]"
      ],
      "metadata": {
        "id": "hRfeFzbMw2-y"
      },
      "execution_count": 484,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Randomly assigning sentiment would result in a score of around 33.34% for this dataset. In my tests, this algorithm consistently score above 40%, with k = 5 even getting as high as 48%."
      ],
      "metadata": {
        "id": "BRlQAOeKDX-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(1, 16, 2):\n",
        "  preds = kNN(k, train, test, ncds)\n",
        "  score = sum([1 for i in range(len(preds)) if preds[i] == test['Sentiment'][i+math.ceil(len(df)*train_split)]])\n",
        "  accuracy = score / len(test)\n",
        "  print(\"Accuracy at k =\", k, \":\", round(accuracy*100, 2), \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKBilGn8zpl9",
        "outputId": "216721d7-ce9e-4e30-b0b0-39abbbcb56e7"
      },
      "execution_count": 485,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy at k = 1 : 47.53 %\n",
            "Accuracy at k = 3 : 46.24 %\n",
            "Accuracy at k = 5 : 48.39 %\n",
            "Accuracy at k = 7 : 47.53 %\n",
            "Accuracy at k = 9 : 45.81 %\n",
            "Accuracy at k = 11 : 45.16 %\n",
            "Accuracy at k = 13 : 45.16 %\n",
            "Accuracy at k = 15 : 44.52 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"twitter+reddit/Twitter_Data.csv\"\n",
        "df = pd.read_csv(file_path, sep=\",\", lineterminator=\"\\n\", names=[\"Sentence\", \"Sentiment\"])\n",
        "\n",
        "df = df.sample(frac = 0.01).reset_index()\n",
        "train_split = 0.75\n",
        "\n",
        "df['Sentence'] = df['Sentence'].astype('string')\n",
        "df['Sentiment'] = df['Sentiment'].astype('int')\n",
        "\n",
        "train = df.loc[0:math.floor((len(df)*train_split))-1]\n",
        "test = df.loc[math.ceil(len(df)*train_split):len(df)]"
      ],
      "metadata": {
        "id": "JQXbqfmRzxDp"
      },
      "execution_count": 512,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even on 1% of the data, this one took more than 5 mins for me"
      ],
      "metadata": {
        "id": "qtiyvAcGEw75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ncds = [[ncd(j, i) for j in train['Sentence']] for i in test['Sentence']]"
      ],
      "metadata": {
        "id": "v9iO0R9bz2fb"
      },
      "execution_count": 513,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Randomly assigning sentiment would result in a score of around 33.34% for this dataset. In my tests, this algorithm consistently score around 40% across all the values of k."
      ],
      "metadata": {
        "id": "XRyo1bN0DmrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(1, 16, 2):\n",
        "  preds = kNN(k, train, test, ncds)\n",
        "  score = sum([1 for i in range(len(preds)) if preds[i] == test['Sentiment'][i+math.ceil(len(df)*train_split)]])\n",
        "  accuracy = score / len(test)\n",
        "  print(\"Accuracy at k =\", k, \":\", round(accuracy*100, 2), \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgSNhN0-z3kT",
        "outputId": "a56a91e8-8a1d-449a-b4f4-c7ee9ee1b015"
      },
      "execution_count": 515,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy at k = 1 : 48.89 %\n",
            "Accuracy at k = 3 : 42.75 %\n",
            "Accuracy at k = 5 : 39.8 %\n",
            "Accuracy at k = 7 : 40.79 %\n",
            "Accuracy at k = 9 : 41.03 %\n",
            "Accuracy at k = 11 : 39.56 %\n",
            "Accuracy at k = 13 : 37.1 %\n",
            "Accuracy at k = 15 : 38.08 %\n"
          ]
        }
      ]
    }
  ]
}